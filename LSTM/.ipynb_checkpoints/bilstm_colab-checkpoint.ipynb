{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZiCDRNNAJAQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib\n",
    "import sys, re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "nEPSkPbSAY1V",
    "outputId": "560477c1-65a2-4f7a-a897-ec7e02449637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "# if this cell prints \"Running on cpu\", you must switch runtime environments\n",
    "# go to Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-j02qXRAJAZ"
   },
   "outputs": [],
   "source": [
    "def read_embeddings(filename, vocab_size=10000):\n",
    "    # get the embedding size from the first embedding\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        word_embedding_dim = len(file.readline().split(\" \")) - 2\n",
    "\n",
    "    vocab = {}\n",
    "\n",
    "    embeddings = np.zeros((vocab_size, word_embedding_dim))\n",
    "\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for idx, line in enumerate(file):\n",
    "            if idx >= vocab_size:\n",
    "                break\n",
    "            cols = line.rstrip().split(\" \")\n",
    "            val = np.array(cols[1:])\n",
    "            char = cols[0]\n",
    "            embeddings[idx] = val\n",
    "            vocab[char] = idx\n",
    "\n",
    "    return torch.FloatTensor(embeddings), vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qx2Sz_-AJAj"
   },
   "outputs": [],
   "source": [
    "# this loads the 10,000 most common char embeddings\n",
    "vocab_size = 10000\n",
    "embeddings, vocab = read_embeddings('gigaword_chn.all.a2b.uni.ite50.txt', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T87McSBVhTf9"
   },
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, filename):\n",
    "        \n",
    "        self.chars, self.tags = self.read_data(filename)\n",
    "        self.chars_chunk = []\n",
    "        self.tags_chunk = []\n",
    "\n",
    "\n",
    "    def read_data(self, book):\n",
    "        \"\"\"\n",
    "        Utility function, loads text file into a list of character and tag strings\n",
    "\n",
    "        Returns:\n",
    "        - chars:    a list of characters\n",
    "        - tags:         a list of tags for each character, where tags[i] contains\n",
    "                        a list of tags (strings) that correspond to the chars in \n",
    "                        chars[i]\n",
    "        \"\"\"\n",
    "        chars = []\n",
    "        tags = []\n",
    "\n",
    "        current_char = []\n",
    "        current_tags = []\n",
    "\n",
    "        book = book.split(\"\\n\")\n",
    "        \n",
    "        for line in book:\n",
    "            if line == \"\":\n",
    "                # print(\"!!!!!\")\n",
    "                if len(current_char) != 0:\n",
    "                    # print(current_char)\n",
    "                    # print(current_tags)\n",
    "                    chars.append(current_char)\n",
    "                    tags.append(current_tags)\n",
    "                    \n",
    "                current_char = []\n",
    "                current_tags = []\n",
    "            else:\n",
    "                columns = line.rstrip().split('\\t')\n",
    "                char = columns[0].lower()\n",
    "                tag = columns[1]\n",
    "                \n",
    "                current_char.append(char)\n",
    "                current_tags.append(tag)\n",
    "    \n",
    "        return chars, tags\n",
    "    \n",
    "        \n",
    "\n",
    "    def get_batches(self, batch_size, vocab, tagset, start, end, omit):\n",
    "        \"\"\"\n",
    "\n",
    "        Batches the data into mini-batches of size `batch_size`\n",
    "\n",
    "        Arguments:\n",
    "        - batch_size:       the desired output batch size\n",
    "        - vocab:            a dictionary mapping char strings to indices\n",
    "        - tagset:           a dictionary mapping tag strings to indices\n",
    "\n",
    "        Outputs:\n",
    "\n",
    "        if is_labeled=True:\n",
    "        - batched_char_indices:     a list of matrices of dimension (batch_size x max_seq_len)\n",
    "        - batched_tag_indices:      a list of matrices of dimension (batch_size x max_seq_len)\n",
    "        - batched_lengths:          a list of arrays of length (batch_size)\n",
    "\n",
    "        batched_char_indices[b] is a (batch_size x max_seq_len) matrix of integers, \n",
    "        containing index representations for characters in the b-th batch in the document. \n",
    "\n",
    "        batched_lengths[b] is a vector of length (batch_size). batched_lengths[b][i] \n",
    "        contains the original char length *before* padding for the i-th char in the currrent batch. \n",
    "\n",
    "        \"\"\"\n",
    "        PAD_INDEX = 0             # reserved for padding words, all chars shorter than max_seq_len should be padded on the right with PAD_INDEX (0).\n",
    "        UNKNOWN_INDEX = 1         # reserved for unknown words, if a char is not in the vocabulary, it gets mapped to UNKNOWN_INDEX (1).\n",
    "        IGNORE_TAG_INDEX = -100   # reserved for padding tags, all tag lists shorter than `max_seq_len` are padded with IGNORE_TAG_INDEX (-100).\n",
    "       \n",
    "        batched_char_indices = []\n",
    "        batched_tag_indices = []\n",
    "        batched_lengths = []\n",
    "        \n",
    "        if omit == -1: # for dev sets\n",
    "            chars = self.chars_chunk[start:end][0]\n",
    "            tags = self.tags_chunk[start:end][0]\n",
    "        else: # for training sets\n",
    "            chars = [self.chars_chunk[i] for i in range(start, end) if i != omit]\n",
    "            tags = [self.tags_chunk[i] for i in range(start, end) if i != omit]\n",
    "            \n",
    "            temp_char = []\n",
    "            temp_tag = []\n",
    "            for i in range(1, len(chars)):\n",
    "                temp_char += chars[i]\n",
    "                temp_tag += tags[i]\n",
    "            chars = temp_char\n",
    "            tags = temp_tag\n",
    "\n",
    "        for num_batch in range(math.ceil(len(chars) / batch_size)):\n",
    "            char_list = np.array(chars[num_batch * batch_size : min((num_batch + 1) * batch_size, len(chars))])\n",
    "            #batched_lengths\n",
    "            length_array = np.zeros(len(char_list))\n",
    "            #batched_char_indices\n",
    "            max_seq_len = len(max(char_list, key=len))\n",
    "            matrix = np.zeros((min(batch_size, len(char_list)), max_seq_len))\n",
    "            for i in range(len(char_list)):\n",
    "                matrix[i] = [vocab[word] if word in vocab else UNKNOWN_INDEX for word in char_list[i]] + [PAD_INDEX for i in range(max_seq_len - len(char_list[i]))]\n",
    "                length_array[i] = len(char_list[i])\n",
    "            batched_char_indices.append(matrix)\n",
    "            batched_lengths.append(length_array)\n",
    "\n",
    "\n",
    "        #batched_tag_indices\n",
    "        for num_batch in range(math.ceil(len(tags) / batch_size)):\n",
    "            tag_list = np.array(tags[num_batch * batch_size : min((num_batch + 1) * batch_size, len(tags))])\n",
    "            max_seq_len = len(max(tag_list, key=len))\n",
    "            matrix = np.zeros((min(batch_size, len(tag_list)), max_seq_len))\n",
    "            for i in range(len(tag_list)):\n",
    "                matrix[i] = [tagset[word] if word in tagset else UNKNOWN_INDEX for word in tag_list[i]] + [IGNORE_TAG_INDEX for i in range(max_seq_len - len(tag_list[i]))]\n",
    "            batched_tag_indices.append(matrix)\n",
    "\n",
    "            \n",
    "        return batched_char_indices, batched_tag_indices, batched_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8M9n2HX4AJA3"
   },
   "outputs": [],
   "source": [
    "def read_tagset(tag_file):\n",
    "    \"\"\"\n",
    "    Utility function, loads tag file into a dictionary from tag string to tag index\n",
    "    \"\"\"\n",
    "    tagset = {}\n",
    "    with open(tag_file, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            columns = line.rstrip().split('\\t')\n",
    "            tag = columns[0]\n",
    "            tag_id = int(columns[1])\n",
    "            tagset[tag] = tag_id\n",
    "\n",
    "    return tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xc1DR64CAJBL"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(true, pred, num_tags):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    - true:       a list of true label values (integers)\n",
    "    - pred:       a list of predicted label values (integers)\n",
    "    - num_tags:   the number of possible tags\n",
    "                true and pred will both contain integers between\n",
    "                0 and num_tags - 1 (inclusive)\n",
    "\n",
    "    Output: \n",
    "    - confusion_matrix:   a (num_tags x num_tags) matrix of integers\n",
    "    confusion_matrix[i][j] = # predictions where true label was i and predicted label was j\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    confusion_matrix = np.zeros((num_tags, num_tags))\n",
    "\n",
    "    for i in range(len(true)):\n",
    "        true_label = true[i]\n",
    "        pred_label = pred[i]\n",
    "        confusion_matrix[true_label][pred_label] += 1\n",
    "   \n",
    "    return confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "def precision(true, pred, num_tags):\n",
    "    \"\"\"\n",
    "    Output: \n",
    "    - precision:  an array of length num_tags, where precision[i] gives the precision of class i\n",
    "    \"\"\"\n",
    "\n",
    "    precision = np.zeros(num_tags)\n",
    "\n",
    "    matrix = confusion_matrix(true, pred, num_tags)\n",
    "    for k in range(num_tags):\n",
    "        TP = matrix[k, k] #kth row: true = k\n",
    "        FP = sum(matrix[:, k]) - matrix[k, k]\n",
    "        precision[k] = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(true, pred, num_tags):\n",
    "    \"\"\"\n",
    "    Output: \n",
    "    - recall:     an array of length num_tags, where recall[i] gives the recall of class i\n",
    "    \"\"\"\n",
    "\n",
    "    recall = np.zeros(num_tags)\n",
    "\n",
    "    matrix = confusion_matrix(true, pred, num_tags)\n",
    "    for k in range(num_tags):\n",
    "        TP = matrix[k, k] #kth row: true = k\n",
    "        FN = sum(matrix[k, :]) - matrix[k, k]\n",
    "        recall[k] = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1_score(true, pred, num_tags):\n",
    "    \"\"\"\n",
    "    Output: \n",
    "    - f1:         an array of length num_tags, where f1[i] gives the recall of class i\n",
    "    \"\"\"\n",
    "\n",
    "    f1 = np.zeros(num_tags)\n",
    "\n",
    "    p = precision(true, pred, num_tags)\n",
    "    r = recall(true, pred, num_tags)\n",
    "    for k in range(num_tags):\n",
    "        f1[k] = 2 * (p[k] * r[k]) / (p[k] + r[k])\n",
    "\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1uy5W2gAJBa"
   },
   "outputs": [],
   "source": [
    "def eval_per_class(model, dev_content, vocab, tagset):\n",
    "    \"\"\"\n",
    "    Prints precision, recall, and F1 for each class in the tagset\n",
    "    \"\"\"\n",
    "    # batch the data\n",
    "    batched_idx, batched_tags, batched_lens = dev_content\n",
    "    # compute idx --> tag from tag --> idx\n",
    "    reverse_tagset = {v: k for k,v in tagset.items()}\n",
    "    # evaluate model on hold-out set\n",
    "    acc, true, pred = model.evaluate(batched_idx, batched_lens, batched_tags, tagset)\n",
    "    true = np.array(true)\n",
    "    pred = np.array(pred)\n",
    "\n",
    "    pr = precision(true, pred, len(tagset))\n",
    "    re = recall(true, pred, len(tagset))\n",
    "    f1 = f1_score(true, pred, len(tagset))\n",
    "\n",
    "    for idx, tag in reverse_tagset.items():\n",
    "        print(\"***********************\")\n",
    "        print(\"TAG: {}\".format(tag))\n",
    "        num_pred = np.sum(pred == idx)\n",
    "        num_true = np.sum(true == idx)\n",
    "        print(\"({} pred, {} true)\".format(num_pred, num_true))\n",
    "\n",
    "        print(\"PRECISION: \\t{:.3f}\".format(pr[idx]))\n",
    "        print(\"RECALL: \\t{:.3f}\".format(re[idx]))\n",
    "        print(\"F1 SCORE: \\t{:.3f}\".format(f1[idx]))\n",
    "    return true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJrPHHRz89J6"
   },
   "outputs": [],
   "source": [
    "def eval_PER(model, dev_content, vocab, tagset):\n",
    "    \"\"\"\n",
    "    Prints precision, recall, and F1 for each class in the tagset\n",
    "    \"\"\"\n",
    "    # batch the data\n",
    "    batched_idx, batched_tags, batched_lens = dev_content\n",
    "    # compute idx --> tag from tag --> idx\n",
    "    reverse_tagset = {v: k for k,v in tagset.items()}\n",
    "    # evaluate model on hold-out set\n",
    "    acc, true, pred = model.evaluate(batched_idx, batched_lens, batched_tags, tagset)\n",
    "    true = np.array(true)\n",
    "    pred = np.array(pred)\n",
    "\n",
    "    pr = precision(true, pred, len(tagset))\n",
    "    re = recall(true, pred, len(tagset))\n",
    "    f1 = f1_score(true, pred, len(tagset))\n",
    "\n",
    "    for idx, tag in reverse_tagset.items():\n",
    "        if tag == \"B-PER\" or tag == \"I-PER\":\n",
    "            print(\"***********************\")\n",
    "            print(\"TAG: {}\".format(tag))\n",
    "            num_pred = np.sum(pred == idx)\n",
    "            num_true = np.sum(true == idx)\n",
    "            print(\"({} pred, {} true)\".format(num_pred, num_true))\n",
    "\n",
    "            print(\"PRECISION: \\t{:.3f}\".format(pr[idx]))\n",
    "            print(\"RECALL: \\t{:.3f}\".format(re[idx]))\n",
    "            print(\"F1 SCORE: \\t{:.3f}\".format(f1[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ct1kHI-cAJBp"
   },
   "outputs": [],
   "source": [
    "def combine(folder):\n",
    "    filenames = [f for f in listdir(folder) if isfile(join(folder, f))]\n",
    "    \n",
    "    out = \"\"\n",
    "    for i in range(len(filenames)):\n",
    "        with open(folder + '/' + filenames[i], encoding='utf-8') as infile: \n",
    "            content = infile.read()\n",
    "            out = out + content\n",
    "        out = out + \"\\n\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VeRYj0ciAJBw"
   },
   "outputs": [],
   "source": [
    "# read the files\n",
    "# all_books = combine('../data/correct_BIO_output')\n",
    "\n",
    "# with open('../data/all_books.txt', 'w', encoding='utf-8') as outfile:\n",
    "#     outfile.write(all_books) \n",
    "    \n",
    "tagset = read_tagset('NER_labels.txt')\n",
    "with open(\"all_books.txt\" ,encoding='utf-8') as file:\n",
    "  all_books = file.read()\n",
    "\n",
    "dataset = Dataset(all_books)\n",
    "\n",
    "BATCH_SIZE = 64 #for stocastic gradient descent purpose\n",
    "\n",
    "# train_batch_idx, train_batch_tags, train_batch_lens = train_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
    "# dev_batch_idx, dev_batch_tags, dev_batch_lens = dev_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
    "# test_batch_idx, test_batch_tags, test_batch_lens = test_dataset.get_batches(BATCH_SIZE, vocab, tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "VgH1F6II4yp5",
    "outputId": "1655199c-a079-4e3c-9e68-1f1eca7dc741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8867\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w7dwF8XdAJCM"
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    An LSTM model for sequence labeling\n",
    "\n",
    "    Initialization Arguments:\n",
    "    - embeddings:   a matrix of size (vocab_size, emb_dim)\n",
    "                  containing pretrained embedding weights\n",
    "    - hidden_dim:   the LSTM's hidden layer size\n",
    "    - tagset_size:  the number of possible output tags\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, embeddings, hidden_dim, tagset_size, bidirectional_flag = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        if bidirectional_flag:\n",
    "          self.hidden_dim = hidden_dim // 2\n",
    "    \n",
    "        self.num_labels = tagset_size\n",
    "\n",
    "        vocab_size = len(embeddings)\n",
    "        embedding_dim = len(embeddings[0])\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embeddings.weight = nn.Parameter(embeddings)\n",
    "        \n",
    "        # Initialize an LSTM layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional = bidirectional_flag, batch_first=True, dropout=0.5, num_layers=3)\n",
    "\n",
    "        # Initialize a single feedforward layer\n",
    "        self.feedlayer = nn.Linear(hidden_dim * 2, tagset_size)\n",
    "\n",
    "    def forward(self, indices, lengths):\n",
    "        \"\"\"\n",
    "        Runs a batched sequence through the model and returns output logits\n",
    "\n",
    "        Arguments:\n",
    "        - indices:  a matrix of size (batch_size x max_seq_len)\n",
    "                    containing the word indices of sentences in the batch\n",
    "        - lengths:  a vector of size (batch_size) containing the\n",
    "                    original lengths of the sequences before padding\n",
    "\n",
    "        Output:\n",
    "        - logits:   a matrix of size (batch_size x max_seq_len x num_tags)\n",
    "                    gives a score to each possible tag for each word\n",
    "                    in each sentence \n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # cast arrays as PyTorch data types and move to GPU memory\n",
    "        indices = torch.LongTensor(indices).to(device)\n",
    "        lengths = torch.LongTensor(lengths).to(device)\n",
    "\n",
    "        # convert word indices to word embeddings\n",
    "        embeddings = self.embeddings(indices)\n",
    "\n",
    "        # pack/pad handles variable length sequence batching\n",
    "        # see here if you're curious: https://gist.github.com/HarshTrivedi/f4e7293e941b17d19058f6fb90ab0fec\n",
    "        packed_input_embs = pack_padded_sequence(embeddings, lengths, batch_first=True, enforce_sorted=False)\n",
    "        # run input through LSTM layer\n",
    "        packed_output, _ = self.lstm(packed_input_embs)\n",
    "        # unpack sequences into original format\n",
    "        padded_output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        logits = self.feedlayer(padded_output)\n",
    "        return logits\n",
    "\n",
    "    def run_training(self, train_content, dev_content, batch_size, vocab, tagset,\n",
    "                         lr=5e-4, num_epochs=100, eval_every=5):\n",
    "        \"\"\"\n",
    "        Trains the model on the training data with a learning rate of lr\n",
    "        for num_epochs. Evaluates the model on the dev data eval_every epochs.\n",
    "\n",
    "        Arguments:\n",
    "        - train_dataset:  Dataset object containing the training data\n",
    "        - dev_dataset:    Dataset object containing the dev data\n",
    "        - batch_size:     batch size for train/dev data\n",
    "        - vocab:          a dictionary mapping word strings to indices\n",
    "        - tagset:         a dictionary mapping tag strings to indices\n",
    "        - lr:             learning rate\n",
    "        - num_epochs:     number of epochs to train for\n",
    "        - eval_every:     evaluation is run eval_every epochs\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#         if str(device) == 'cpu':\n",
    "#             print(\"Training only supported in GPU environment\")\n",
    "#             return\n",
    "\n",
    "        # clear unreferenced data/models from GPU memory \n",
    "        torch.cuda.empty_cache()\n",
    "        # move model to GPU memory\n",
    "        self.to(device)\n",
    "\n",
    "        # set the optimizer (Adam) and loss function (CrossEnt)\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        loss_function = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "        # batch training and dev data\n",
    "        train_batch_idx, train_batch_tags, train_batch_lens = train_content\n",
    "        dev_batch_idx, dev_batch_tags, dev_batch_lens = dev_content\n",
    "\n",
    "        print(\"**** TRAINING *****\")\n",
    "        for i in range(num_epochs):\n",
    "            # sets the model in train mode\n",
    "            self.train()\n",
    "\n",
    "            total_loss = 0\n",
    "            for b in range(len(train_batch_idx)):\n",
    "                # compute the logits\n",
    "                logits = self.forward(train_batch_idx[b], train_batch_lens[b])\n",
    "                # move labels to GPU memory\n",
    "                labels = torch.LongTensor(train_batch_tags[b]).to(device)\n",
    "                # compute the loss with respect to true labels\n",
    "                loss = loss_function(logits.view(-1, len(tagset)), labels.view(-1))\n",
    "                total_loss += loss\n",
    "                # propagate gradients backward\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # set model gradients to zero before performing next forward pass\n",
    "                self.zero_grad()\n",
    "\n",
    "            #print(\"Epoch {} | Loss: {}\".format(i, total_loss))\n",
    "\n",
    "            if (i + 1) % eval_every == 0:\n",
    "                print(\"**** EVALUATION *****\")\n",
    "                # sets the model in evaluate mode (no gradients)\n",
    "                self.eval()\n",
    "                # compute dev f1 score\n",
    "                acc, true, pred = self.evaluate(dev_batch_idx, dev_batch_lens, dev_batch_tags, tagset)\n",
    "                print(\"Dev Accuracy: {}\".format(acc))\n",
    "                print(\"**********************\")\n",
    "                \n",
    "        return acc, true, pred\n",
    "\n",
    "                \n",
    "                \n",
    "    def evaluate(self, batched_sentences, batched_lengths, batched_labels, tagset):\n",
    "        \"\"\"\n",
    "        Evaluate the model's predictions on the provided dataset. \n",
    "\n",
    "        Arguments:\n",
    "        - batched_sentences:  a list of matrices, each of size (batch_size x max_seq_len),\n",
    "                              containing the word indices of sentences in the batch\n",
    "        - batched_lengths:    a list of vectors, each of size (batch_size), containing the\n",
    "                              original lengths of the sequences before padding\n",
    "        - batched_labels:     a list of matrices, each of size (batch_size x max_seq_len),\n",
    "                              containing the tag indices corresponding to sentences in the batch\n",
    "        - num_tags:           the number of possible output tags\n",
    "\n",
    "        Output:\n",
    "        - accuracy:           the model's prediction accuracy\n",
    "        - all_true_labels:    a flattened list of all true labels\n",
    "        - all_predictions:    a flattened list of all of the model's corresponding predictions\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        all_true_labels = []\n",
    "        all_predictions = []\n",
    "\n",
    "        for b in range(len(batched_sentences)):\n",
    "            logits = self.forward(batched_sentences[b], batched_lengths[b])\n",
    "            batch_predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "            batch_size, _ = batched_sentences[b].shape\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                tags = batched_labels[b][i]\n",
    "                preds = batch_predictions[i]\n",
    "\n",
    "                seq_len = int(batched_lengths[b][i])\n",
    "                for j in range(seq_len):\n",
    "                    all_predictions.append(int(preds[j]))\n",
    "                    all_true_labels.append(int(tags[j]))\n",
    "\n",
    "\n",
    "        acc = accuracy(all_true_labels, all_predictions)\n",
    "\n",
    "        return acc, all_true_labels, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kcRQHggmAJCV"
   },
   "outputs": [],
   "source": [
    "def accuracy(true, pred):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "    - accuracy:   the prediction accuracy\n",
    "    \"\"\"\n",
    "    true = np.array(true)\n",
    "    pred = np.array(pred)\n",
    "\n",
    "    num_correct = sum(true == pred)\n",
    "    num_total = len(true)\n",
    "\n",
    "    return num_correct / num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Ue2Fx1AJCd"
   },
   "outputs": [],
   "source": [
    "# np.random.seed(100)\n",
    "\n",
    "# HIDDEN_SIZE = 64\n",
    "# # intialize a new LSTMTagger model\n",
    "# model = LSTMTagger(embeddings, HIDDEN_SIZE, len(tagset))\n",
    "# # train the model\n",
    "# model.run_training(train_dataset, dev_dataset, BATCH_SIZE, vocab, tagset,   \n",
    "#                    lr=5e-4, num_epochs=25, eval_every=5)\n",
    "# eval_per_class(model, dev_dataset, vocab, tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A740wvqeAJCn"
   },
   "outputs": [],
   "source": [
    "# eval_per_class(model, dev_dataset, vocab, tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "85IXytabAJCu",
    "outputId": "d0a6c99b-bac4-432b-faaf-4546c4e4ae1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** TRAINING *****\n",
      "**** EVALUATION *****\n",
      "Dev Accuracy: 0.9808389435525634\n",
      "**********************\n",
      "============ K-Fold ============\n",
      "#Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************\n",
      "TAG: PER\n",
      "(913 pred, 922 true)\n",
      "PRECISION: \t0.893\n",
      "RECALL: \t0.884\n",
      "F1 SCORE: \t0.888\n",
      "***********************\n",
      "TAG: NORP\n",
      "(33 pred, 47 true)\n",
      "PRECISION: \t0.515\n",
      "RECALL: \t0.362\n",
      "F1 SCORE: \t0.425\n",
      "***********************\n",
      "TAG: FAC\n",
      "(28 pred, 63 true)\n",
      "PRECISION: \t0.500\n",
      "RECALL: \t0.222\n",
      "F1 SCORE: \t0.308\n",
      "***********************\n",
      "TAG: ORG\n",
      "(13 pred, 28 true)\n",
      "PRECISION: \t0.077\n",
      "RECALL: \t0.036\n",
      "F1 SCORE: \t0.049\n",
      "***********************\n",
      "TAG: GPE\n",
      "(54 pred, 39 true)\n",
      "PRECISION: \t0.407\n",
      "RECALL: \t0.564\n",
      "F1 SCORE: \t0.473\n",
      "***********************\n",
      "TAG: LOC\n",
      "(68 pred, 33 true)\n",
      "PRECISION: \t0.279\n",
      "RECALL: \t0.576\n",
      "F1 SCORE: \t0.376\n",
      "***********************\n",
      "TAG: PRODUCT\n",
      "(0 pred, 15 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: EVENT\n",
      "(2 pred, 11 true)\n",
      "PRECISION: \t1.000\n",
      "RECALL: \t0.182\n",
      "F1 SCORE: \t0.308\n",
      "***********************\n",
      "TAG: ART\n",
      "(46 pred, 54 true)\n",
      "PRECISION: \t0.891\n",
      "RECALL: \t0.759\n",
      "F1 SCORE: \t0.820\n",
      "***********************\n",
      "TAG: LAW\n",
      "(0 pred, 0 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: LANGUAGE\n",
      "(8 pred, 2 true)\n",
      "PRECISION: \t0.250\n",
      "RECALL: \t1.000\n",
      "F1 SCORE: \t0.400\n",
      "***********************\n",
      "TAG: O\n",
      "(22007 pred, 21958 true)\n",
      "PRECISION: \t0.990\n",
      "RECALL: \t0.993\n",
      "F1 SCORE: \t0.991\n",
      "================================\n",
      "**** TRAINING *****\n",
      "**** EVALUATION *****\n",
      "Dev Accuracy: 0.9828530502190765\n",
      "**********************\n",
      "============ K-Fold ============\n",
      "#Fold: 1\n",
      "***********************\n",
      "TAG: PER\n",
      "(946 pred, 974 true)\n",
      "PRECISION: \t0.919\n",
      "RECALL: \t0.892\n",
      "F1 SCORE: \t0.905\n",
      "***********************\n",
      "TAG: NORP\n",
      "(33 pred, 36 true)\n",
      "PRECISION: \t0.697\n",
      "RECALL: \t0.639\n",
      "F1 SCORE: \t0.667\n",
      "***********************\n",
      "TAG: FAC\n",
      "(23 pred, 78 true)\n",
      "PRECISION: \t0.652\n",
      "RECALL: \t0.192\n",
      "F1 SCORE: \t0.297\n",
      "***********************\n",
      "TAG: ORG\n",
      "(5 pred, 19 true)\n",
      "PRECISION: \t0.200\n",
      "RECALL: \t0.053\n",
      "F1 SCORE: \t0.083\n",
      "***********************\n",
      "TAG: GPE\n",
      "(57 pred, 72 true)\n",
      "PRECISION: \t0.632\n",
      "RECALL: \t0.500\n",
      "F1 SCORE: \t0.558\n",
      "***********************\n",
      "TAG: LOC\n",
      "(58 pred, 57 true)\n",
      "PRECISION: \t0.483\n",
      "RECALL: \t0.491\n",
      "F1 SCORE: \t0.487\n",
      "***********************\n",
      "TAG: PRODUCT\n",
      "(0 pred, 21 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: EVENT\n",
      "(1 pred, 4 true)\n",
      "PRECISION: \t1.000\n",
      "RECALL: \t0.250\n",
      "F1 SCORE: \t0.400\n",
      "***********************\n",
      "TAG: ART\n",
      "(19 pred, 24 true)\n",
      "PRECISION: \t0.737\n",
      "RECALL: \t0.583\n",
      "F1 SCORE: \t0.651\n",
      "***********************\n",
      "TAG: LAW\n",
      "(0 pred, 0 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: LANGUAGE\n",
      "(2 pred, 3 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: O\n",
      "(22592 pred, 22448 true)\n",
      "PRECISION: \t0.989\n",
      "RECALL: \t0.995\n",
      "F1 SCORE: \t0.992\n",
      "================================\n",
      "**** TRAINING *****\n",
      "**** EVALUATION *****\n",
      "Dev Accuracy: 0.9800936768149883\n",
      "**********************\n",
      "============ K-Fold ============\n",
      "#Fold: 2\n",
      "***********************\n",
      "TAG: PER\n",
      "(884 pred, 949 true)\n",
      "PRECISION: \t0.911\n",
      "RECALL: \t0.848\n",
      "F1 SCORE: \t0.878\n",
      "***********************\n",
      "TAG: NORP\n",
      "(55 pred, 32 true)\n",
      "PRECISION: \t0.291\n",
      "RECALL: \t0.500\n",
      "F1 SCORE: \t0.368\n",
      "***********************\n",
      "TAG: FAC\n",
      "(52 pred, 61 true)\n",
      "PRECISION: \t0.519\n",
      "RECALL: \t0.443\n",
      "F1 SCORE: \t0.478\n",
      "***********************\n",
      "TAG: ORG\n",
      "(33 pred, 21 true)\n",
      "PRECISION: \t0.364\n",
      "RECALL: \t0.571\n",
      "F1 SCORE: \t0.444\n",
      "***********************\n",
      "TAG: GPE\n",
      "(84 pred, 91 true)\n",
      "PRECISION: \t0.679\n",
      "RECALL: \t0.626\n",
      "F1 SCORE: \t0.651\n",
      "***********************\n",
      "TAG: LOC\n",
      "(60 pred, 66 true)\n",
      "PRECISION: \t0.300\n",
      "RECALL: \t0.273\n",
      "F1 SCORE: \t0.286\n",
      "***********************\n",
      "TAG: PRODUCT\n",
      "(3 pred, 12 true)\n",
      "PRECISION: \t0.333\n",
      "RECALL: \t0.083\n",
      "F1 SCORE: \t0.133\n",
      "***********************\n",
      "TAG: EVENT\n",
      "(1 pred, 21 true)\n",
      "PRECISION: \t1.000\n",
      "RECALL: \t0.048\n",
      "F1 SCORE: \t0.091\n",
      "***********************\n",
      "TAG: ART\n",
      "(46 pred, 38 true)\n",
      "PRECISION: \t0.696\n",
      "RECALL: \t0.842\n",
      "F1 SCORE: \t0.762\n",
      "***********************\n",
      "TAG: LAW\n",
      "(0 pred, 0 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: LANGUAGE\n",
      "(1 pred, 8 true)\n",
      "PRECISION: \t1.000\n",
      "RECALL: \t0.125\n",
      "F1 SCORE: \t0.222\n",
      "***********************\n",
      "TAG: O\n",
      "(21839 pred, 21759 true)\n",
      "PRECISION: \t0.990\n",
      "RECALL: \t0.994\n",
      "F1 SCORE: \t0.992\n",
      "================================\n",
      "**** TRAINING *****\n",
      "**** EVALUATION *****\n",
      "Dev Accuracy: 0.9759379382889201\n",
      "**********************\n",
      "============ K-Fold ============\n",
      "#Fold: 3\n",
      "***********************\n",
      "TAG: PER\n",
      "(989 pred, 973 true)\n",
      "PRECISION: \t0.856\n",
      "RECALL: \t0.871\n",
      "F1 SCORE: \t0.863\n",
      "***********************\n",
      "TAG: NORP\n",
      "(51 pred, 31 true)\n",
      "PRECISION: \t0.235\n",
      "RECALL: \t0.387\n",
      "F1 SCORE: \t0.293\n",
      "***********************\n",
      "TAG: FAC\n",
      "(21 pred, 72 true)\n",
      "PRECISION: \t0.762\n",
      "RECALL: \t0.222\n",
      "F1 SCORE: \t0.344\n",
      "***********************\n",
      "TAG: ORG\n",
      "(28 pred, 26 true)\n",
      "PRECISION: \t0.321\n",
      "RECALL: \t0.346\n",
      "F1 SCORE: \t0.333\n",
      "***********************\n",
      "TAG: GPE\n",
      "(120 pred, 101 true)\n",
      "PRECISION: \t0.558\n",
      "RECALL: \t0.663\n",
      "F1 SCORE: \t0.606\n",
      "***********************\n",
      "TAG: LOC\n",
      "(51 pred, 37 true)\n",
      "PRECISION: \t0.333\n",
      "RECALL: \t0.459\n",
      "F1 SCORE: \t0.386\n",
      "***********************\n",
      "TAG: PRODUCT\n",
      "(0 pred, 25 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: EVENT\n",
      "(0 pred, 16 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: ART\n",
      "(65 pred, 74 true)\n",
      "PRECISION: \t0.815\n",
      "RECALL: \t0.716\n",
      "F1 SCORE: \t0.763\n",
      "***********************\n",
      "TAG: LAW\n",
      "(0 pred, 0 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: LANGUAGE\n",
      "(2 pred, 8 true)\n",
      "PRECISION: \t0.500\n",
      "RECALL: \t0.125\n",
      "F1 SCORE: \t0.200\n",
      "***********************\n",
      "TAG: O\n",
      "(21489 pred, 21453 true)\n",
      "PRECISION: \t0.989\n",
      "RECALL: \t0.990\n",
      "F1 SCORE: \t0.989\n",
      "================================\n",
      "**** TRAINING *****\n",
      "**** EVALUATION *****\n",
      "Dev Accuracy: 0.9831667543398211\n",
      "**********************\n",
      "============ K-Fold ============\n",
      "#Fold: 4\n",
      "***********************\n",
      "TAG: PER\n",
      "(937 pred, 984 true)\n",
      "PRECISION: \t0.908\n",
      "RECALL: \t0.865\n",
      "F1 SCORE: \t0.886\n",
      "***********************\n",
      "TAG: NORP\n",
      "(37 pred, 29 true)\n",
      "PRECISION: \t0.568\n",
      "RECALL: \t0.724\n",
      "F1 SCORE: \t0.636\n",
      "***********************\n",
      "TAG: FAC\n",
      "(17 pred, 23 true)\n",
      "PRECISION: \t0.588\n",
      "RECALL: \t0.435\n",
      "F1 SCORE: \t0.500\n",
      "***********************\n",
      "TAG: ORG\n",
      "(29 pred, 36 true)\n",
      "PRECISION: \t0.759\n",
      "RECALL: \t0.611\n",
      "F1 SCORE: \t0.677\n",
      "***********************\n",
      "TAG: GPE\n",
      "(80 pred, 73 true)\n",
      "PRECISION: \t0.588\n",
      "RECALL: \t0.644\n",
      "F1 SCORE: \t0.614\n",
      "***********************\n",
      "TAG: LOC\n",
      "(59 pred, 57 true)\n",
      "PRECISION: \t0.525\n",
      "RECALL: \t0.544\n",
      "F1 SCORE: \t0.534\n",
      "***********************\n",
      "TAG: PRODUCT\n",
      "(1 pred, 12 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: EVENT\n",
      "(0 pred, 6 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: ART\n",
      "(55 pred, 53 true)\n",
      "PRECISION: \t0.782\n",
      "RECALL: \t0.811\n",
      "F1 SCORE: \t0.796\n",
      "***********************\n",
      "TAG: LAW\n",
      "(0 pred, 0 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: LANGUAGE\n",
      "(4 pred, 6 true)\n",
      "PRECISION: \t0.500\n",
      "RECALL: \t0.333\n",
      "F1 SCORE: \t0.400\n",
      "***********************\n",
      "TAG: O\n",
      "(21593 pred, 21533 true)\n",
      "PRECISION: \t0.991\n",
      "RECALL: \t0.994\n",
      "F1 SCORE: \t0.992\n",
      "================================\n",
      "**** TRAINING *****\n",
      "**** EVALUATION *****\n",
      "Dev Accuracy: 0.9817534103744895\n",
      "**********************\n",
      "============ K-Fold ============\n",
      "#Fold: 5\n",
      "***********************\n",
      "TAG: PER\n",
      "(832 pred, 922 true)\n",
      "PRECISION: \t0.927\n",
      "RECALL: \t0.836\n",
      "F1 SCORE: \t0.879\n",
      "***********************\n",
      "TAG: NORP\n",
      "(45 pred, 35 true)\n",
      "PRECISION: \t0.511\n",
      "RECALL: \t0.657\n",
      "F1 SCORE: \t0.575\n",
      "***********************\n",
      "TAG: FAC\n",
      "(11 pred, 38 true)\n",
      "PRECISION: \t0.545\n",
      "RECALL: \t0.158\n",
      "F1 SCORE: \t0.245\n",
      "***********************\n",
      "TAG: ORG\n",
      "(5 pred, 25 true)\n",
      "PRECISION: \t0.800\n",
      "RECALL: \t0.160\n",
      "F1 SCORE: \t0.267\n",
      "***********************\n",
      "TAG: GPE\n",
      "(52 pred, 86 true)\n",
      "PRECISION: \t0.731\n",
      "RECALL: \t0.442\n",
      "F1 SCORE: \t0.551\n",
      "***********************\n",
      "TAG: LOC\n",
      "(58 pred, 40 true)\n",
      "PRECISION: \t0.224\n",
      "RECALL: \t0.325\n",
      "F1 SCORE: \t0.265\n",
      "***********************\n",
      "TAG: PRODUCT\n",
      "(0 pred, 4 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: EVENT\n",
      "(3 pred, 10 true)\n",
      "PRECISION: \t0.667\n",
      "RECALL: \t0.200\n",
      "F1 SCORE: \t0.308\n",
      "***********************\n",
      "TAG: ART\n",
      "(38 pred, 46 true)\n",
      "PRECISION: \t0.789\n",
      "RECALL: \t0.652\n",
      "F1 SCORE: \t0.714\n",
      "***********************\n",
      "TAG: LAW\n",
      "(0 pred, 3 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: LANGUAGE\n",
      "(0 pred, 8 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: O\n",
      "(21974 pred, 21801 true)\n",
      "PRECISION: \t0.988\n",
      "RECALL: \t0.996\n",
      "F1 SCORE: \t0.992\n",
      "================================\n",
      "**** TRAINING *****\n",
      "**** EVALUATION *****\n",
      "Dev Accuracy: 0.9805307487196852\n",
      "**********************\n",
      "============ K-Fold ============\n",
      "#Fold: 6\n",
      "***********************\n",
      "TAG: PER\n",
      "(870 pred, 944 true)\n",
      "PRECISION: \t0.898\n",
      "RECALL: \t0.827\n",
      "F1 SCORE: \t0.861\n",
      "***********************\n",
      "TAG: NORP\n",
      "(36 pred, 40 true)\n",
      "PRECISION: \t0.500\n",
      "RECALL: \t0.450\n",
      "F1 SCORE: \t0.474\n",
      "***********************\n",
      "TAG: FAC\n",
      "(20 pred, 42 true)\n",
      "PRECISION: \t0.750\n",
      "RECALL: \t0.357\n",
      "F1 SCORE: \t0.484\n",
      "***********************\n",
      "TAG: ORG\n",
      "(3 pred, 34 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: GPE\n",
      "(72 pred, 74 true)\n",
      "PRECISION: \t0.653\n",
      "RECALL: \t0.635\n",
      "F1 SCORE: \t0.644\n",
      "***********************\n",
      "TAG: LOC\n",
      "(41 pred, 24 true)\n",
      "PRECISION: \t0.415\n",
      "RECALL: \t0.708\n",
      "F1 SCORE: \t0.523\n",
      "***********************\n",
      "TAG: PRODUCT\n",
      "(2 pred, 8 true)\n",
      "PRECISION: \t1.000\n",
      "RECALL: \t0.250\n",
      "F1 SCORE: \t0.400\n",
      "***********************\n",
      "TAG: EVENT\n",
      "(4 pred, 6 true)\n",
      "PRECISION: \t0.500\n",
      "RECALL: \t0.333\n",
      "F1 SCORE: \t0.400\n",
      "***********************\n",
      "TAG: ART\n",
      "(42 pred, 94 true)\n",
      "PRECISION: \t0.881\n",
      "RECALL: \t0.394\n",
      "F1 SCORE: \t0.544\n",
      "***********************\n",
      "TAG: LAW\n",
      "(0 pred, 0 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: LANGUAGE\n",
      "(6 pred, 3 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: O\n",
      "(22531 pred, 22358 true)\n",
      "PRECISION: \t0.987\n",
      "RECALL: \t0.995\n",
      "F1 SCORE: \t0.991\n",
      "================================\n",
      "**** TRAINING *****\n",
      "**** EVALUATION *****\n",
      "Dev Accuracy: 0.9823949724517906\n",
      "**********************\n",
      "============ K-Fold ============\n",
      "#Fold: 7\n",
      "***********************\n",
      "TAG: PER\n",
      "(803 pred, 855 true)\n",
      "PRECISION: \t0.885\n",
      "RECALL: \t0.832\n",
      "F1 SCORE: \t0.858\n",
      "***********************\n",
      "TAG: NORP\n",
      "(51 pred, 36 true)\n",
      "PRECISION: \t0.569\n",
      "RECALL: \t0.806\n",
      "F1 SCORE: \t0.667\n",
      "***********************\n",
      "TAG: FAC\n",
      "(20 pred, 58 true)\n",
      "PRECISION: \t0.800\n",
      "RECALL: \t0.276\n",
      "F1 SCORE: \t0.410\n",
      "***********************\n",
      "TAG: ORG\n",
      "(23 pred, 33 true)\n",
      "PRECISION: \t0.304\n",
      "RECALL: \t0.212\n",
      "F1 SCORE: \t0.250\n",
      "***********************\n",
      "TAG: GPE\n",
      "(34 pred, 55 true)\n",
      "PRECISION: \t0.676\n",
      "RECALL: \t0.418\n",
      "F1 SCORE: \t0.517\n",
      "***********************\n",
      "TAG: LOC\n",
      "(28 pred, 38 true)\n",
      "PRECISION: \t0.464\n",
      "RECALL: \t0.342\n",
      "F1 SCORE: \t0.394\n",
      "***********************\n",
      "TAG: PRODUCT\n",
      "(0 pred, 4 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: EVENT\n",
      "(9 pred, 15 true)\n",
      "PRECISION: \t0.556\n",
      "RECALL: \t0.333\n",
      "F1 SCORE: \t0.417\n",
      "***********************\n",
      "TAG: ART\n",
      "(41 pred, 40 true)\n",
      "PRECISION: \t0.756\n",
      "RECALL: \t0.775\n",
      "F1 SCORE: \t0.765\n",
      "***********************\n",
      "TAG: LAW\n",
      "(0 pred, 0 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: LANGUAGE\n",
      "(2 pred, 9 true)\n",
      "PRECISION: \t0.500\n",
      "RECALL: \t0.111\n",
      "F1 SCORE: \t0.182\n",
      "***********************\n",
      "TAG: O\n",
      "(22221 pred, 22089 true)\n",
      "PRECISION: \t0.989\n",
      "RECALL: \t0.995\n",
      "F1 SCORE: \t0.992\n",
      "================================\n",
      "**** TRAINING *****\n",
      "**** EVALUATION *****\n",
      "Dev Accuracy: 0.9797117147142143\n",
      "**********************\n",
      "============ K-Fold ============\n",
      "#Fold: 8\n",
      "***********************\n",
      "TAG: PER\n",
      "(944 pred, 1035 true)\n",
      "PRECISION: \t0.905\n",
      "RECALL: \t0.825\n",
      "F1 SCORE: \t0.863\n",
      "***********************\n",
      "TAG: NORP\n",
      "(40 pred, 34 true)\n",
      "PRECISION: \t0.575\n",
      "RECALL: \t0.676\n",
      "F1 SCORE: \t0.622\n",
      "***********************\n",
      "TAG: FAC\n",
      "(37 pred, 59 true)\n",
      "PRECISION: \t0.703\n",
      "RECALL: \t0.441\n",
      "F1 SCORE: \t0.542\n",
      "***********************\n",
      "TAG: ORG\n",
      "(14 pred, 22 true)\n",
      "PRECISION: \t0.500\n",
      "RECALL: \t0.318\n",
      "F1 SCORE: \t0.389\n",
      "***********************\n",
      "TAG: GPE\n",
      "(85 pred, 71 true)\n",
      "PRECISION: \t0.518\n",
      "RECALL: \t0.620\n",
      "F1 SCORE: \t0.564\n",
      "***********************\n",
      "TAG: LOC\n",
      "(43 pred, 70 true)\n",
      "PRECISION: \t0.349\n",
      "RECALL: \t0.214\n",
      "F1 SCORE: \t0.265\n",
      "***********************\n",
      "TAG: PRODUCT\n",
      "(3 pred, 0 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: EVENT\n",
      "(4 pred, 5 true)\n",
      "PRECISION: \t0.500\n",
      "RECALL: \t0.400\n",
      "F1 SCORE: \t0.444\n",
      "***********************\n",
      "TAG: ART\n",
      "(20 pred, 46 true)\n",
      "PRECISION: \t0.850\n",
      "RECALL: \t0.370\n",
      "F1 SCORE: \t0.515\n",
      "***********************\n",
      "TAG: LAW\n",
      "(0 pred, 0 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: LANGUAGE\n",
      "(0 pred, 3 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: O\n",
      "(22814 pred, 22659 true)\n",
      "PRECISION: \t0.988\n",
      "RECALL: \t0.994\n",
      "F1 SCORE: \t0.991\n",
      "================================\n",
      "**** TRAINING *****\n",
      "**** EVALUATION *****\n",
      "Dev Accuracy: 0.9805996472663139\n",
      "**********************\n",
      "============ K-Fold ============\n",
      "#Fold: 9\n",
      "***********************\n",
      "TAG: PER\n",
      "(1054 pred, 1010 true)\n",
      "PRECISION: \t0.858\n",
      "RECALL: \t0.895\n",
      "F1 SCORE: \t0.876\n",
      "***********************\n",
      "TAG: NORP\n",
      "(36 pred, 51 true)\n",
      "PRECISION: \t0.528\n",
      "RECALL: \t0.373\n",
      "F1 SCORE: \t0.437\n",
      "***********************\n",
      "TAG: FAC\n",
      "(33 pred, 55 true)\n",
      "PRECISION: \t0.697\n",
      "RECALL: \t0.418\n",
      "F1 SCORE: \t0.523\n",
      "***********************\n",
      "TAG: ORG\n",
      "(26 pred, 31 true)\n",
      "PRECISION: \t0.769\n",
      "RECALL: \t0.645\n",
      "F1 SCORE: \t0.702\n",
      "***********************\n",
      "TAG: GPE\n",
      "(53 pred, 64 true)\n",
      "PRECISION: \t0.604\n",
      "RECALL: \t0.500\n",
      "F1 SCORE: \t0.547\n",
      "***********************\n",
      "TAG: LOC\n",
      "(73 pred, 41 true)\n",
      "PRECISION: \t0.342\n",
      "RECALL: \t0.610\n",
      "F1 SCORE: \t0.439\n",
      "***********************\n",
      "TAG: PRODUCT\n",
      "(5 pred, 8 true)\n",
      "PRECISION: \t1.000\n",
      "RECALL: \t0.625\n",
      "F1 SCORE: \t0.769\n",
      "***********************\n",
      "TAG: EVENT\n",
      "(4 pred, 13 true)\n",
      "PRECISION: \t1.000\n",
      "RECALL: \t0.308\n",
      "F1 SCORE: \t0.471\n",
      "***********************\n",
      "TAG: ART\n",
      "(51 pred, 80 true)\n",
      "PRECISION: \t0.961\n",
      "RECALL: \t0.613\n",
      "F1 SCORE: \t0.748\n",
      "***********************\n",
      "TAG: LAW\n",
      "(0 pred, 0 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: LANGUAGE\n",
      "(6 pred, 12 true)\n",
      "PRECISION: \t0.167\n",
      "RECALL: \t0.083\n",
      "F1 SCORE: \t0.111\n",
      "***********************\n",
      "TAG: O\n",
      "(22473 pred, 22449 true)\n",
      "PRECISION: \t0.991\n",
      "RECALL: \t0.992\n",
      "F1 SCORE: \t0.991\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "#Perform K-fold Cross Validation and train the model\n",
    "np.random.seed(100) \n",
    "shuffle = np.random.permutation(range(len(dataset.chars)))\n",
    "\n",
    "chars = [dataset.chars[i] for i in shuffle]\n",
    "length = int(len(chars) / 12)\n",
    "tags = [dataset.tags[i] for i in shuffle]\n",
    "dataset.tags_chunk = []\n",
    "dataset.chars_chunk = []\n",
    "\n",
    "\n",
    "#Divide data into 10 chunks\n",
    "for k in range(12):\n",
    "    if k != 11:\n",
    "        fold_chars = chars[length*k : length*(k + 1)]\n",
    "        fold_tags = tags[length*k : length*(k + 1)]\n",
    "        dataset.chars_chunk.append(fold_chars)\n",
    "        dataset.tags_chunk.append(fold_tags)\n",
    "    else:\n",
    "        fold_chars = chars[length*k :]\n",
    "        fold_tags = tags[length*k :]\n",
    "        dataset.chars_chunk.append(fold_chars)\n",
    "        dataset.tags_chunk.append(fold_tags)\n",
    "        \n",
    "\n",
    "#Loop 10 times, each time training with different chunks\n",
    "dev_accuracy = []\n",
    "true_array = np.array([])\n",
    "pred_array = np.array([])\n",
    "HIDDEN_SIZE = 128\n",
    "for k in range(10):\n",
    "    train_batch_idx, train_batch_tags, train_batch_lens = dataset.get_batches(BATCH_SIZE, vocab, tagset, 0, 10, k)\n",
    "    dev_batch_idx, dev_batch_tags, dev_batch_lens = dataset.get_batches(BATCH_SIZE, vocab, tagset, k, k + 1, -1)\n",
    "    train_content = (train_batch_idx, train_batch_tags, train_batch_lens)\n",
    "    dev_content = (dev_batch_idx, dev_batch_tags, dev_batch_lens)\n",
    "    \n",
    "    # intialize a new BiLSTM model\n",
    "    model = BiLSTM(embeddings, HIDDEN_SIZE, len(tagset))\n",
    "    # train the model\n",
    "    acc, true, pred = model.run_training(train_content, dev_content, BATCH_SIZE, vocab, tagset,   \n",
    "                       lr=5e-4, num_epochs=25, eval_every=25)\n",
    "    dev_accuracy.append(acc)\n",
    "    print(\"============ K-Fold ============\")\n",
    "    print(\"#Fold: {}\".format(k))\n",
    "    true_item, pred_item = eval_per_class(model, dev_content, vocab, tagset)\n",
    "    true_array = np.append(true_array, true_item)\n",
    "    pred_array = np.append(pred_array, pred_item)\n",
    "    # print(\"\"\"\"TRUE Array\"\"\")\n",
    "    # print(len(true_array))\n",
    "    # print(\"\"\"\"Pred Array\"\"\")\n",
    "    # print(len(pred_array))\n",
    "    # print(\"\"\"\"Len-Tagset\"\"\")\n",
    "    # print(len_tagset)\n",
    "    print(\"================================\")\n",
    "    \n",
    "    \n",
    "test_batch_idx, test_batch_tags, test_batch_lens = dataset.get_batches(BATCH_SIZE, vocab, tagset, 10, 12, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBbghmZt15QR"
   },
   "outputs": [],
   "source": [
    "true_array = np.array([int(x) for x in true_array])\n",
    "pred_array = np.array([int(x) for x in pred_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "F_0TYR1bUX_v",
    "outputId": "e827b8e0-dc90-49b2-bea3-ac2e6a22cf61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************\n",
      "TAG: PER\n",
      "(9172 pred, 9568 true)\n",
      "PRECISION: \t0.895\n",
      "RECALL: \t0.858\n",
      "F1 SCORE: \t0.876\n",
      "***********************\n",
      "TAG: NORP\n",
      "(417 pred, 371 true)\n",
      "PRECISION: \t0.482\n",
      "RECALL: \t0.542\n",
      "F1 SCORE: \t0.510\n",
      "***********************\n",
      "TAG: FAC\n",
      "(262 pred, 549 true)\n",
      "PRECISION: \t0.641\n",
      "RECALL: \t0.306\n",
      "F1 SCORE: \t0.414\n",
      "***********************\n",
      "TAG: ORG\n",
      "(179 pred, 275 true)\n",
      "PRECISION: \t0.464\n",
      "RECALL: \t0.302\n",
      "F1 SCORE: \t0.366\n",
      "***********************\n",
      "TAG: GPE\n",
      "(691 pred, 726 true)\n",
      "PRECISION: \t0.598\n",
      "RECALL: \t0.569\n",
      "F1 SCORE: \t0.583\n",
      "***********************\n",
      "TAG: LOC\n",
      "(539 pred, 463 true)\n",
      "PRECISION: \t0.364\n",
      "RECALL: \t0.423\n",
      "F1 SCORE: \t0.391\n",
      "***********************\n",
      "TAG: PRODUCT\n",
      "(14 pred, 109 true)\n",
      "PRECISION: \t0.571\n",
      "RECALL: \t0.073\n",
      "F1 SCORE: \t0.130\n",
      "***********************\n",
      "TAG: EVENT\n",
      "(28 pred, 107 true)\n",
      "PRECISION: \t0.679\n",
      "RECALL: \t0.178\n",
      "F1 SCORE: \t0.281\n",
      "***********************\n",
      "TAG: ART\n",
      "(423 pred, 549 true)\n",
      "PRECISION: \t0.820\n",
      "RECALL: \t0.632\n",
      "F1 SCORE: \t0.714\n",
      "***********************\n",
      "TAG: LAW\n",
      "(0 pred, 3 true)\n",
      "PRECISION: \t0.000\n",
      "RECALL: \t0.000\n",
      "F1 SCORE: \tnan\n",
      "***********************\n",
      "TAG: LANGUAGE\n",
      "(31 pred, 62 true)\n",
      "PRECISION: \t0.258\n",
      "RECALL: \t0.129\n",
      "F1 SCORE: \t0.172\n",
      "***********************\n",
      "TAG: O\n",
      "(221533 pred, 220507 true)\n",
      "PRECISION: \t0.989\n",
      "RECALL: \t0.994\n",
      "F1 SCORE: \t0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# Compute final precision/recall/f1-score\n",
    "pr = precision(true_array, pred_array, len(tagset))\n",
    "re = recall(true_array, pred_array, len(tagset))\n",
    "f1 = f1_score(true_array, pred_array, len(tagset))\n",
    "reverse_tagset = {v: k for k,v in tagset.items()}\n",
    "\n",
    "for idx, tag in reverse_tagset.items():\n",
    "    print(\"***********************\")\n",
    "    print(\"TAG: {}\".format(tag))\n",
    "    num_pred = np.sum(pred_array == idx)\n",
    "    num_true = np.sum(true_array == idx)\n",
    "    print(\"({} pred, {} true)\".format(num_pred, num_true))\n",
    "\n",
    "    print(\"PRECISION: \\t{:.3f}\".format(pr[idx]))\n",
    "    print(\"RECALL: \\t{:.3f}\".format(re[idx]))\n",
    "    print(\"F1 SCORE: \\t{:.3f}\".format(f1[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2O-n_LC11SK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bilstm_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
